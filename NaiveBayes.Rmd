---
title: "NaiveBayes"
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'NaiveBayes.html'))})
---

```{r, include=FALSE, echo=FALSE, message=FALSE}
#Downloading the required packages
library(dplyr)
library(readr)
library(plyr)
library(gmodels)
library(ggplot2)
library(ggpubr)
library(pdp)
library(klaR)
library(Information)
library(gridExtra)
library(kableExtra)
library(knitr)
library(glmnet)
library(tidyverse)
library(caret)
library(pROC)
library(data.table)
library(scales)
library(openxlsx)
library(png)
library(knitr)
library(kableExtra)
library(broom)
```

```{r, include=FALSE, echo=FALSE, message=FALSE}
german_credit<-read_delim("http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data",delim = " ",col_names = FALSE)
headers=c("Status_checking_account","Duration_in_month","Credit_history",
          "Purpose","Credit_amount","Savings_account_bonds","Present_employment_since",
          "Installment_rate_in_percentage_of_disp_income","Personal_status_and_sex",
          "Guarantors","Present_residence_since","Property","Age",
          "Other_installment_plans","Housing","Number_of_existing_credits_at_this_bank",
          "Job","Number_of_dependants","Telephone","foreign_worker","Credit_Risk")
colnames(german_credit)<-headers
#gdat<-german_credit
```

```{r, include=FALSE, echo=FALSE, message=FALSE}
gdat<-german_credit
gdat$Status_checking_account<-factor(mapvalues(gdat$Status_checking_account,c("A11","A12","A13","A14"),c("lt_0","lt_200","gte_200","No_account")),
                                     levels =c("No_account","lt_0","lt_200","gte_200"))
gdat$Credit_history<-factor(mapvalues(gdat$Credit_history,c("A30","A31","A32","A33","A34"),c("No_credit_due","All_paid_duly","All_existing_paid_duly","delayed_in_past","Critical")),
                            levels = c("Critical","delayed_in_past","No_credit_due","All_paid_duly","All_existing_paid_duly"))
gdat$Purpose<-factor(mapvalues(gdat$Purpose,c("A40","A41","A42","A43","A44","A45","A46","A47","A48","A49","A410"),c("New.car", "Used.car", "Furniture", "Television", "Appliances", "Repairs", "Education", "Vacation", "Retraining", "Business", "Others")))

gdat$Savings_account_bonds<-factor(mapvalues(gdat$Savings_account_bonds,c("A61","A62","A63","A64","A65"),c("lt_100","100_500","500_1000","gt_1000","No_savings")),
                                   levels=c("No_savings","lt_100","100_500","500_1000","gt_1000"))

gdat$Present_employment_since<-factor(mapvalues(gdat$Present_employment_since,c("A71","A72","A73","A74","A75"),c("Unemployed","1_yr","4_yr","7_yr","gt_7_yr")),
                                      levels=c("Unemployed","1_yr","4_yr","7_yr","gt_7_yr"))

gdat$Personal_status_and_sex<-factor(mapvalues(gdat$Personal_status_and_sex,c("A91","A92","A93","A94","A95"),c("Male.divorced","Female.divorced","male.single","male.married","female.single")),
                                     levels=c("female.single","Male.divorced","Female.divorced","male.single","male.married"))

gdat$Guarantors<-factor(mapvalues(gdat$Guarantors,c("A101","A102","A103"),c("none","co_applicant","guarantor")),levels=c("none","co_applicant","guarantor"))

gdat$Property<-factor(mapvalues(gdat$Property,c("A121","A122","A123","A124"),c("Real.estate","insurance","car","No.property")),levels=c("No.property","Real.estate","insurance","car"))

gdat$Other_installment_plans<-factor(mapvalues(gdat$Other_installment_plans,c("A141","A142","A143"),c("banks","stores","None")),levels=c("None","banks","stores"))

gdat$Housing<-factor(mapvalues(gdat$Housing,c("A151","A152","A153"),c("Rent","Own","Free")),levels =c("Free","Rent","Own"))

gdat$Job<-factor(mapvalues(gdat$Job,c("A171","A172","A173","A174"),c("Unemployed_NonRes","Unskilled_Res","skilled","management")),
                 levels=c("Unemployed_NonRes","Unskilled_Res","skilled","management"))

gdat$Telephone<-factor(mapvalues(gdat$Telephone,c("A191","A192"),c("No","Yes")))

gdat$foreign_worker<-factor(mapvalues(gdat$foreign_worker,c("A201","A202"),c("Yes","No")))

gdat$Number_of_dependants<-factor(mapvalues(gdat$Number_of_dependants,c(2,1),c("lt_2","gt_2")),levels=c("lt_2","gt_2"))

gdat$Installment_rate_in_percentage_of_disp_income<-factor(mapvalues(gdat$Installment_rate_in_percentage_of_disp_income,c(4,3,2,1),c("0_20","20_25","25_35","35_plus")),
                                                           levels =c("0_20","20_25","25_35","35_plus"))

gdat$Present_residence_since <-factor(mapvalues(gdat$Present_residence_since ,c("1","2","3","4"),c("lt_1_yr","1_4yr","4_7yr","gt_7_yr")),levels =c("lt_1_yr","1_4yr","4_7yr","gt_7_yr"))

gdat$Credit_Risk<-factor(mapvalues(gdat$Credit_Risk,c(2,1),c("Bad","Good")))

```


```{r,message=FALSE,echo=FALSE,include=FALSE}
confusion_roc_function<-function(log_model,training_df,testing_df,cutoff=0.5,model="logistic"){
  if(model=="logistic"){
    train_df1<-training_df
    test_df1<-test_df
    probabilities_test <- predict(log_model, test_df1[,-21])
    probabilities_train <- predict(log_model, train_df1[,-21])
    predicted.classes_test <- as.factor(if_else(probabilities_test > cutoff, "Good", "Bad"))
    predicted.classes_train <- as.factor(if_else(probabilities_train > cutoff, "Good", "Bad"))
    observed.classes_test <- test_df1$Credit_Risk
    observed.classes_train <- train_df1$Credit_Risk
    # Train Accuracy
    cm.Train<-caret::confusionMatrix(predicted.classes_train,observed.classes_train,positive="Good")
    caret::confusionMatrix(predicted.classes_train,observed.classes_train,positive="Good")
    # Test Accuracy
    cm.Test<-caret::confusionMatrix(predicted.classes_test,observed.classes_test,positive="Good")
    caret::confusionMatrix(predicted.classes_test,observed.classes_test,positive="Good")
    #quartz()
    pROC_obj_train <- pROC::roc(train_df$Credit_Risk,probabilities_train,
                          smoothed = TRUE,
                          # arguments for ci
                          ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                          # arguments for plot
                          plot=FALSE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                          print.auc=TRUE, show.thres=TRUE)
    #sens.ci_train <- ci.se(pROC_obj_train)
    #train_roc<- plot(sens.ci_train, type="shape", col="lightblue")
    pROC_obj_test <- pROC::roc(test_df$Credit_Risk,probabilities_test,
                          smoothed = TRUE,
                          # arguments for ci
                          ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                          # arguments for plot
                          plot=FALSE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                          print.auc=TRUE, show.thres=TRUE)
    #sens.ci_test <- ci.se(pROC_obj_test)
    
    train_p <- ggroc(pROC_obj_train, alpha = 0.5, colour = "red", linetype = 1, size = 2)+
  ggtitle(paste0('ROC Curve: Train set', '(AUC = ', round(pROC_obj_train$auc,4), ')'))+ geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1),
                 color="darkgrey", linetype="dashed")

test_p <- ggroc(pROC_obj_test, alpha = 0.5, colour = "red", linetype = 1, size = 2)+
  ggtitle(paste0('ROC Curve: Test set', '(AUC = ', round(pROC_obj_test$auc,4), ')'))+
  geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1),
                 color="darkgrey", linetype="dashed")

    #test_roc<- plot(sens.ci_test, type="shape", col="lightblue")
    return(list(CM_TEST=cm.Test,CM_TRAIN=cm.Train,plot_TRAIN=pROC_obj_train,plot_TEST=pROC_obj_test,train_p,test_p))
  }
  if(model=="RF"){
    probabilities_test <- predict(log_model, testing_df[,names(testing_df) != "Credit_Risk"])
    probabilities_train <- predict(log_model, training_df[,names(training_df) != "Credit_Risk"])
    observed.classes_test <- testing_df$Credit_Risk
    observed.classes_train <- training_df$Credit_Risk
    cm.Test<-caret::confusionMatrix(probabilities_test,observed.classes_test,positive="Good")
    cm.Train<-caret::confusionMatrix(probabilities_train,observed.classes_train,positive="Good")
    
    train_pred_1 <- predict(log_model, newdata = training_df,type="prob")[,2]
    test_pred_1 <- predict(log_model, newdata = testing_df,type="prob")[,2]
    train_roc<-pROC::roc( observed.classes_train,train_pred_1,
           smoothed = TRUE,
           # arguments for ci
           ci=TRUE, ci.alpha=0.9, stratified=FALSE,
           # arguments for plot
           plot=FALSE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                          print.auc=TRUE, show.thres=TRUE)
    
    test_roc<-pROC::roc( observed.classes_test,test_pred_1,
                      smoothed = TRUE,
                      # arguments for ci
                      ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                      # arguments for plot
                      plot=FALSE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                          print.auc=TRUE, show.thres=TRUE)

    return(list(CM_TEST=cm.Test,CM_TRAIN=cm.Train,AUC_train=train_roc,AUC_test=test_roc))
    
  }
  if(model=="NB"){
    probabilities_test <- predict(log_model, testing_df[,names(testing_df) != "Credit_Risk"])
    probabilities_train <- predict(log_model, training_df[,names(training_df) != "Credit_Risk"])
    observed.classes_test <- testing_df$Credit_Risk
    observed.classes_train <- training_df$Credit_Risk
    cm.Test<-caret::confusionMatrix(probabilities_test,observed.classes_test,positive="Good")
    cm.Train<-caret::confusionMatrix(probabilities_train,observed.classes_train,positive="Good")
        train_pred_1 <- predict(log_model, newdata = training_df,type="prob")[,2]
    test_pred_1 <- predict(log_model, newdata = testing_df,type="prob")[,2]
    train_roc<-pROC::roc( observed.classes_train,train_pred_1,
           smoothed = TRUE,
           # arguments for ci
           ci=TRUE, ci.alpha=0.9, stratified=FALSE,
           # arguments for plot
           plot=FALSE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                          print.auc=TRUE, show.thres=TRUE)
    
    test_roc<-pROC::roc( observed.classes_test,test_pred_1,
                      smoothed = TRUE,
                      # arguments for ci
                      ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                      # arguments for plot
                      plot=FALSE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                          print.auc=TRUE, show.thres=TRUE)
    train_p <- ggroc(train_roc, alpha = 0.5, colour = "red", linetype = 1, size = 2)+
  ggtitle(paste0('ROC Curve: Train set', '(AUC = ', round(train_roc$auc,4), ')'))+ geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1),
                 color="darkgrey", linetype="dashed")

test_p <- ggroc(test_roc, alpha = 0.5, colour = "red", linetype = 1, size = 2)+
  ggtitle(paste0('ROC Curve: Test set', '(AUC = ', round(test_roc$auc,4), ')'))+
  geom_segment(aes(x = 1, xend = 0, y = 0, yend = 1),
                 color="darkgrey", linetype="dashed")

    
    return(list(CM_TEST=cm.Test,CM_TRAIN=cm.Train,AUC_train=train_roc,AUC_test=test_roc,train_p,test_p))
  }
}

## Function for optimal cut off value
AccuracyCutoffInfo <- function( train, test, predict, actual )
{
  # change the cutoff value's range as you please 
  cutoff <- seq( .4, .8, by = .05 )
  
  accuracy <- lapply( cutoff, function(c)
  {
    # use the confusionMatrix from the caret package
    cm_train <- caret::confusionMatrix(as.factor(as.numeric( train[[predict]] > c )),as.factor(as.numeric( train[[actual]])-1))
    cm_test  <- caret::confusionMatrix(as.factor(as.numeric( test[[predict]] > c )),as.factor(as.numeric( test[[actual]])-1))
    
    dt <- data.table( cutoff = c,
                      train  = cm_train$overall[["Accuracy"]],
                      test   = cm_test$overall[["Accuracy"]] )
    return(dt)
  }) %>% rbindlist()
  
  # visualize the accuracy of the train and test set for different cutoff value 
  # accuracy in percentage.
  accuracy_long <- gather( accuracy, "data", "accuracy", -1 )
  
  plot <- ggplot( accuracy_long, aes( cutoff, accuracy, group = data, color = data ) ) + 
    geom_line( size = 1 ) + geom_point( size = 3 ) +
    scale_y_continuous( label = percent ) +
    ggtitle( "Train/Test Accuracy for Different Cutoff" ) + theme_light()
  
  return( list( data = accuracy, plot = plot ) )
}
```

### Naive Bayes with all the variables

\
• Building a Naive Bayes Model with all the Predictors

```{r, echo=FALSE, message=FALSE,include=FALSE}
gdat_log<- as.data.frame(unclass(gdat))
str(gdat_log)
## 75% of the sample size
smp_size <- floor(0.70 * nrow(gdat))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(gdat_log)), size = smp_size)
train_df <- gdat_log[train_ind, ]
test_df <- gdat_log[-train_ind, ]
dim(train_df)
dim(test_df)
```


```{r,message=FALSE,echo=FALSE,warning=FALSE}

german.naive = caret::train(train_df[,names(train_df) != "Credit_Risk"],train_df$Credit_Risk,'nb',trControl=trainControl(method='cv',number=10))

```

• Tables below show Conditional Probability tables (CPT) for each category of the variable in Naive Bayes. 

• For Categorical Variables CPT can be interpreted, for example in case of "Credit_history", as the probability of the customer being labeled as "Bad" given that all existing loans have been paid duly, is 0.5686

• For numeric variables, normal distribution is assumed. Mean, SD and z-scores are calculated and probabilities are estimated.
\
```{r,message=FALSE,echo=FALSE,results='asis'}
#german.naive$finalModel$tables

for(i in rownames(summary(german.naive$finalModel$tables))[-c(2,5,13,16)]){
 print(knitr::kable(as.matrix(german.naive$finalModel$tables[i][[1]]),caption = paste0(i)) %>% kable_paper("hover", full_width = F,html_font = "Cambria",bootstrap_options = "striped",fixed_thead = T))
}
```

\
• Variable Importance Measures from Naive Bayes Model
\

```{r,message=FALSE,echo=FALSE}
X <- varImp(german.naive)

X$importance %>% rownames_to_column("Variable") %>%
  arrange(desc(Good)) %>% dplyr::select(Variable,Good) %>% 
  top_n(20) %>% kable(col.names = c("Variable","Importance")) %>%
  kable_paper("hover", full_width = F,html_font = "Cambria",bootstrap_options = "striped",fixed_thead = T) 
```

\
• Variable importance plot showing importance on x-axis and variable names on the y-axis
\

```{r,message=FALSE,echo=FALSE}
plot(X)
```
\
• Train set confusion matrix and other performance measures
\
```{r, message=FALSE,echo=FALSE,warning=FALSE}
nb_full<-confusion_roc_function(german.naive,train_df,test_df,model="NB")

kable(as.matrix(nb_full$CM_TRAIN),caption = "TRAIN FIT") %>% kable_paper("hover", full_width = F,html_font = "Cambria",bootstrap_options = "striped",fixed_thead = T)  

tidy(nb_full$CM_TRAIN)[-c(3),c(1,3)]%>%kable(caption = "TRAIN FIT PERFORMANCE") %>% kable_paper("hover", full_width = F,html_font = "Cambria",bootstrap_options = "striped",fixed_thead = T)  
#log_full_mofrl[[5]]
nb_full[[5]]
```
\
• Test set confusion matrix and other performance measures
\
```{r, message=FALSE,echo=FALSE,warning=FALSE}
kable(as.matrix(nb_full$CM_TEST),caption = "TEST FIT") %>% kable_paper("hover", full_width = F,html_font = "Cambria",bootstrap_options = "striped",fixed_thead = T)  

tidy(nb_full$CM_TEST)[-c(3),c(1,3)]%>%kable(caption = "TEST FIT PERFORMANCE") %>% kable_paper("hover", full_width = F,html_font = "Cambria",bootstrap_options = "striped",fixed_thead = T)  

nb_full[[6]]

```

### Naive Bayes model with significant Variables

• Model with significant variables

• Train and test set accuracy is given below

```{r,message=FALSE,echo=FALSE, warning=FALSE}
#Building Final Model with selected variables.
important_columns_nb<-c("Age","Credit_amount","Duration_in_month","Telephone","Job","Personal_status_and_sex","Present_employment_since","Property","Purpose","Savings_account_bonds","Status_checking_account","Present_residence_since","Installment_rate_in_percentage_of_disp_income","Credit_Risk")

important_columns_nb %>% kable(col.names = "Significant Variables") %>% kable_paper("hover", full_width = F,html_font = "Cambria",bootstrap_options = "striped",fixed_thead = T) 
```


```{r,message=FALSE,echo=FALSE,include=FALSE, warning=FALSE}
subset_imp_var_nb<-gdat_log[important_columns_nb]
smp_size <- floor(0.70 * nrow(gdat))
## set the seed to make your partition reproducible
set.seed(45)
train_ind <- sample(seq_len(nrow(subset_imp_var_nb)), size = smp_size)
train_df_subset_nb <- subset_imp_var_nb[train_ind, ]
test_df_subset_nb <- subset_imp_var_nb[-train_ind, ]

```


```{r, message=FALSE,echo=FALSE,warning=FALSE}
german.naive_sig = caret::train(train_df_subset_nb[,names(train_df_subset_nb) != "Credit_Risk"],train_df_subset_nb$Credit_Risk,'nb',trControl=trainControl(method='cv',number=10))
```


```{r,message=FALSE,echo=FALSE,warning=FALSE}
nb_sig<-confusion_roc_function(german.naive_sig,train_df_subset_nb,test_df_subset_nb,model="NB")

kable(as.matrix(nb_sig$CM_TRAIN),caption = "TRAIN FIT") %>% kable_paper("hover", full_width = F,html_font = "Cambria",bootstrap_options = "striped",fixed_thead = T)  

tidy(nb_sig$CM_TRAIN)[-c(3),c(1,3)]%>%kable(caption = "TRAIN FIT PERFORMANCE") %>% kable_paper("hover", full_width = F,html_font = "Cambria",bootstrap_options = "striped",fixed_thead = T)  
#log_full_mofrl[[5]]
kable(as.matrix(nb_sig$CM_TEST),caption = "TEST FIT") %>% kable_paper("hover", full_width = F,html_font = "Cambria",bootstrap_options = "striped",fixed_thead = T)  

tidy(nb_sig$CM_TEST)[-c(3),c(1,3)]%>%kable(caption = "TEST FIT PERFORMANCE") %>% kable_paper("hover", full_width = F,html_font = "Cambria",bootstrap_options = "striped",fixed_thead = T)  
```



